<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>– troubleshoot</title><link>/tags/troubleshoot/</link><description>Recent content in troubleshoot on</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 28 Dec 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/troubleshoot/index.xml" rel="self" type="application/rss+xml"/><item><title>Tutorials: Operations Runbook</title><link>/tutorials/operations-runbook/</link><pubDate>Wed, 28 Dec 2022 00:00:00 +0000</pubDate><guid>/tutorials/operations-runbook/</guid><description/></item><item><title>Tutorials: Cluster Failover Response</title><link>/tutorials/operations-runbook/cluster-failover-response/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/operations-runbook/cluster-failover-response/</guid><description>
&lt;div class="pageinfo pageinfo-primary">
&lt;p>When the active (master) member of the &lt;a href="/docs/clusters/">cluster&lt;/a> goes unhealthy the standby member will take over the active role. This process should be automatic and not require manual intervention. However, in certain circumstances, such as the unexpected failover of a public gateway, it is worth investigating to confirm traffic is in a healthy state.&lt;/p>
&lt;/div>
&lt;h3 id="possible-messages">Possible Messages&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Master role assumed - failover&lt;/p>
&lt;ul>
&lt;li>Indicates the master role has moved from the designated master (primary) to the backup/secondary &lt;a href="/docs/nodes/">node&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Master role reclaimed by expected master&lt;/p>
&lt;ul>
&lt;li>Indicates the master role has returned to the designated master&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="failover-process">Failover Process&lt;/h3>
&lt;p>Below is a brief description events that occur during a failover process:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The &lt;a href="/docs/nodes/">node&lt;/a> assuming the master role will ARP to the network that it now owns the &lt;a href="/docs/clusters/">Cluster&lt;/a> Virtual IP (VIP)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;a href="/docs/domain/virtual-networks/routes/">Domain route&lt;/a> table will update that the assuming &lt;a href="/docs/nodes/">node&lt;/a> should receive all traffic for the &lt;a href="/docs/clusters/">cluster&lt;/a> (&lt;em>clustername-master&lt;/em>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The assuming &lt;a href="/docs/nodes/">node&lt;/a> will load all NAT entries associated with the &lt;a href="/docs/clusters/">cluster&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="response-process">Response Process&lt;/h3>
&lt;p>After a failover or failback it is necessary to verify that traffic is flowing appropriately.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Login to the portal and navigate to the affected &lt;a href="/docs/clusters/">cluster’s&lt;/a> page&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Verify that only a single &lt;a href="/docs/nodes/">node&lt;/a> shows as master&lt;/p>
&lt;/li>
&lt;li>
&lt;p>On the &lt;code>Configuration&lt;/code> → &lt;code>Network&lt;/code> tab note the &lt;a href="/docs/clusters/">cluster&lt;/a> VIP&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="cluster-virtual-ip2.png" alt="img">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Click on the indicated current master&lt;/p>
&lt;p>a. Verify the VPN Route Table shows&lt;/p>
&lt;pre>&lt;code>i. Navigate to the `Configuration` → `VPN` tab
ii. Launch the &amp;quot;View Virtual Route Table&amp;quot; tool
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="virtual-network-tools.png" alt="img">&lt;/p>
&lt;pre>&lt;code>iii. Verify that routes show as “available true”
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="routing-tables.png" alt="img">&lt;/p>
&lt;pre>&lt;code> 1. If the cluster is a gateway cluster there may be many routes and not all be active, just confirm many show as available.
2. The route to the management VIP for the other node in the cluster will always be false.
&lt;/code>&lt;/pre>
&lt;p>b. Verify traffic is flowing through the appropriate node.&lt;/p>
&lt;pre>&lt;code>i. Navigate to the `Configuration` → `Network` tab
ii. Confirm the interface associated with the Cluster VIP is selected
3. For single interface nodes: ETH0 / Network Adapter 1 - WAN Adapter
4. For dual interface nodes: ETH1 / Network Adapter 2 - LAN Adapter
iii. Open the `Sniff Interface Traffic` tool.
5. Set the filter to “host clusterVIP” without quotes and replacing clusterVIP with the appropriate Cluster virtual IP. Click `start session`.
6. Confirm that you see traffic flowing through the interface. **Continue monitoring for several minutes to confirm the traffic is maintained.**
7. Leave the Sniff Interface Tool running while completing the next step
iv. Repeat steps i-iii on the node that **is not** currently indicated as the master.
1.You want to verify there is **no traffic for the cluster VIP running through the non-master node**.
8. You may see a periodic ARP from the cluster master, but that should be it.
&lt;/code>&lt;/pre>
&lt;ol>
&lt;li>
&lt;p>Compare traffic volume before and after the failover&lt;/p>
&lt;p>a. If the event was a failover and failback compare traffic from the current master&lt;/p>
&lt;p>b. If the event was a failover but has not failed back you will need to compare traffic volume on the current master to the volume on the previous master&lt;/p>
&lt;pre>&lt;code> i. e.g if traffic failed from node1 to node2, compare node1’s traffic prior to the failover to the volume of traffic on node2 after the failover
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol></description></item><item><title>Tutorials: Control Plane Disconnect</title><link>/tutorials/operations-runbook/control-plane-disconnect/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/operations-runbook/control-plane-disconnect/</guid><description>
&lt;blockquote>
&lt;p>When the Control Plane is disconnected there is no way to utilize remote tools to resolve the issue so you will need to contact the End-user technical resource for the site to troubleshoot&lt;/p>
&lt;/blockquote>
&lt;p>When troubleshooting the control plane it is a good idea to familiarize yourself with the [Edge Node Startup &amp;amp; Update Communication Process].&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th> Network Requirements &lt;/th>
&lt;/tr>
&lt;tr>
&lt;td>
In order to connect to the Trustgrid Control Plane, the following &lt;strong>outbound traffic&lt;/strong> must be allowed from the node’s configured primary interface IP address &lt;br/>
&lt;ul>
&lt;li>TCP Port 443 and TCP/UDP 8443 to:&lt;/li>
&lt;ul>
&lt;li>35.171.100.16/28&lt;/li>
&lt;li>34.223.12.192/28&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>TCP/UDP Port 53 to the configured DNS servers. These DNS servers must be able to resolve DNS requests for the trustgrid.io domain&lt;/li>
&lt;/ul>
&lt;/table>
&lt;ol>
&lt;li>
&lt;p>Triage the total site connectivity to see if actions can be taken to restore functionality for the edge site while troubleshooting the specific node&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Confirm with the site tech:&lt;/p>
&lt;p>a. There are no known power or internet issues at the site&lt;/p>
&lt;p>b. No changes have been made to any firewalls between the Trustgrid node and the internet (if applicable). In order to connect the Trustgrid node must have access to the Network Requirements defined above.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Have the site tech attempt to ping the inside interface IP address(es) to see if the device is showing as powered up and online. If the site is using a single-interface configuration this would be the Network Adapter 1 - WAN Interface IP(s) in the portal.&lt;/p>
&lt;p>a. If the ping is successful you have determined the device has power and that the operating system and Trustgrid software are running. In this case, you can focus on internet side issues.&lt;/p>
&lt;p>b. If the ping fails, work with the site tech to:&lt;/p>
&lt;pre>&lt;code> i. Confirm the node is powered on
ii. Connect directly to the network of the inside interface and attempt ping from there. They should also connect directly to the inside interface and statically configure an IP in the same network.
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Attempt power cycling the node by removing power and returning from physical devices or using the hypervisor management tools for virtual nodes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Connect to the console of the device&lt;/p>
&lt;p>a. A normal node looks something like this&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="normal-node.png" alt="img">&lt;/p>
&lt;pre>&lt;code>i. Work with the onsite tech to login to the Trustgrid Local Console Utility. This tools will display connectivity status and allow you to alter the WAN/outside IP settings if needed.
&lt;/code>&lt;/pre>
&lt;p>b. If you see a screen like below attempt rebooting the device to restore connectivity. If that works contact Trustgrid support so we can investigate further.&lt;/p>
&lt;p>&lt;img src="more-node.png" alt="img">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Disconnect the cable from the WAN/Outside port of the Trustgrid node and connect to a laptop NIC. Statically assign the same IP and DNS settings that the Trustgrid node is using. Confirm the following:&lt;/p>
&lt;p>a. Using &lt;code>nslookup&lt;/code> or &lt;code>dig&lt;/code> to confirm you can resolve zuul.trustgrid.io&lt;/p>
&lt;p>b. Open a browser and navigate to &lt;a href="https://zuul.trustgrid.io:8443">https://zuul.trustgrid.io:8443&lt;/a>&lt;/p>
&lt;pre>&lt;code> i. If the device can connect to that server and port you should see a warning like this because Trustgrid uses its own Certificate Authority (CA)
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="link.png" alt="img">&lt;/p>
&lt;pre>&lt;code> 1. Click `Not Secure` and then click `Certificate (invalid)`
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="certificate-invalid.png" alt="img">&lt;/p>
&lt;pre>&lt;code> 1. You should expect to see a chain like the below.
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="chain.png" alt="img">&lt;/p>
&lt;pre>&lt;code> a. If there are any different certificates or CAs that indicates something like DPI-SSL/HTTPS Proxy is interfering with the handsake. See [this page] for resolution requirements.
ii. If the browser says it cannot connect this indicates a firewall or routing issue upstream.
&lt;/code>&lt;/pre>
&lt;ol>
&lt;li>
&lt;p>If possible, capture traffic between the Trustgrid node and the internet. Specifically, the capture should filter to only see traffic from the Trustgrid node’s IP address and TCP port 8443 and TCP/UDP port 53. Common problems seen include:&lt;/p>
&lt;p>a. Blocked DNS - Edge Node Behavior When DNS Fails&lt;/p>
&lt;p>b. Blocked port 8443 to the Trustgrid Networks - Edge Node Behavior When Port 8443 to Trustgrid Public Networks is Blocked&lt;/p>
&lt;p>c. DPI-SSL or HTTPS altering the TLS certificate chain - Edge Node Behavior When SSL / TLS Certificate is Altered&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h1 id="need-proper-links-to-use-and-need-to-find-how-to-add-links-to-indent-format">&lt;strong>NEED PROPER LINKS TO USE AND NEED TO FIND HOW TO ADD LINKS TO INDENT FORMAT&lt;/strong>&lt;/h1></description></item><item><title>Tutorials: Node Down Response</title><link>/tutorials/operations-runbook/node-down-response/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/operations-runbook/node-down-response/</guid><description>
&lt;div class="pageinfo pageinfo-primary">
&lt;p>This process is intended to help customer support personnel quickly identify the scope of a &lt;a href="/docs/nodes/">node&lt;/a> down problem and get services back online as quickly as possible.&lt;/p>
&lt;/div>
&lt;h3 id="node-down-triage">Node Down Triage&lt;/h3>
&lt;h4 id="triage-checklist">Triage Checklist&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Determine Production Status of the Trustgrid Node&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Confirm High Availability or Disaster Recover is Functioning&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If clustered, is the partner active and working&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If there is a second site, confirm if it is active&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Determine the type of outage (Control Plane, Data Plane or Both)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="determine-production-status-of-the-trustgrid-node">Determine Production Status of the Trustgrid Node&lt;/h3>
&lt;p>Use the &lt;a href="/docs/nodes/tags/prod-status-tag/%7D">Production Status Tags&lt;/a> to determine if the &lt;a href="/docs/nodes/">node&lt;/a> is in use and expected to be online.&lt;/p>
&lt;h3 id="confirm-high-availability-or-disaster-recover-is-functioning">Confirm High Availability or Disaster Recover is Functioning&lt;/h3>
&lt;p>Before troubleshooting why a &lt;a href="/docs/nodes/">node&lt;/a> is down we should determine if the services it provided can be provided in the interim by a cluster member or devices at a secondary/disaster-recovery site.&lt;/p>
&lt;h5 id="is-the-node-a-cluster-member">Is the Node a Cluster Member&lt;/h5>
&lt;ul>
&lt;li>
&lt;p>Check if partner member is online:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If Yes:&lt;/p>
&lt;pre>&lt;code>- Confirm partner member is now active and operating normally.
- The issue is limited to this specific Node. This could be its power input, the hardware or operating system, configuration, or its internet connection (if different than partner member).
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>If No:&lt;/p>
&lt;pre>&lt;code>- Possible site-level issue including power or internet provider
- Proceed to Secondary / DR Site
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h5 id="is-there-a-secondary--dr-site-for-this-nodecluster">Is there a Secondary / DR Site for this Node/Cluster?&lt;/h5>
&lt;ul>
&lt;li>
&lt;p>Are the &lt;a href="/docs/nodes/">nodes&lt;/a> deployed at the secondary site online in the Trustgrid?&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If No:&lt;/p>
&lt;pre>&lt;code>- Confirm nodes for other end-user sites are not also offline which might indicate a wider spread issue. Escalate to Trustgrid Support if you suspect a major issue with the Trustgrid system.
- If limited to a single customer it is recommended to contact that customer immediately. They may be experiencing an outage or performing maintenance.
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>If Yes:&lt;/p>
&lt;pre>&lt;code>- If the customer is configured for Automatic Failover between sites, verify that traffic is flowing through the active member at the secondary site.
- If the customer is configured for Manual Failover you will need to adjust the route destination to point to the secondary site.
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="determine-connectivity-status-of-the-trustgrid-node">Determine Connectivity Status of the Trustgrid Node&lt;/h3>
&lt;p>Because Trustgrid provides independent control and data planes, there are a few ways it can manifest as “down”:&lt;/p>
&lt;tr>
&lt;th>Control Plane Down&lt;/th>
&lt;td>The &lt;a href="/docs/nodes/">node&lt;/a> appears offline from within the Trustgrid portal. This indicates that the &lt;a href="/docs/nodes/">node&lt;/a> shutdown or has not sent a heartbeat notification to Trustgrid within the past 10 minutes.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;th>Data Plane Down&lt;/th>
&lt;td>The &lt;a href="/docs/nodes/">node&lt;/a> appears online from within the portal but reports it is unable to connect to one or more gateway nodes. This can be indicated by the Data Plane Status indicator when viewing the &lt;a href="/docs/nodes/">node&lt;/a> in the portal, or by receiving a “Gateway Connectivity Health Check” failure &lt;a href="/docs/alarms/events/">event&lt;/a> notification. Both of these only work if the Control Plane is currently working.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;th>Both Control and Data Plane Down&lt;/th>
&lt;td>In this situation the &lt;a href="/docs/nodes/">node&lt;/a> appears down in the Trustgrid Portal and users/applications are unable to reach services across the data plane between the Gateway and Edge sites. This is the most common scenario. While the Data Plane is most critical for the services provided across the device, first priority should be restoring the Control Plane connection so that additional troubleshooting tools are available. Often this process also uncovers the reason the data plane is down.&lt;/td>
&lt;/tr></description></item><item><title>Tutorials: Site Failover</title><link>/tutorials/operations-runbook/site-failover/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/operations-runbook/site-failover/</guid><description>
&lt;div class="pageinfo pageinfo-primary">
&lt;p>The below processes should be used to move traffic between sites in event of a complete site down scenario. This is handled by the Virtual Network Route Table.&lt;/p>
&lt;/div>
&lt;div class="alert alert-primary" role="alert">
In the examples below, xxxEdgeCluster is the primary site and xxx-edge3 is the secondary/disaster recovery site.
&lt;/div>
&lt;h3 id="manual-failover">Manual Failover&lt;/h3>
&lt;p>When a customer has selected manual failover, a portal user will need to adjust the destination of all &lt;a href="/docs/domain/virtual-networks/routes/">routes&lt;/a> currently pointed at the failed site.&lt;/p>
&lt;h4 id="failing-over">Failing Over&lt;/h4>
&lt;blockquote>
&lt;p>There will usually be &lt;a href="/docs/domain/virtual-networks/routes/">routes&lt;/a> for the &lt;a href="/docs/nodes/">nodes&amp;rsquo;&lt;/a> Virtual Management IP. These should not be changed in this process.&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>
&lt;p>In the portal, navigate to &lt;code>Domain&lt;/code> → &lt;code>Virtual Networks&lt;/code> and then select the appropriate Virtual network.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;code>Routes&lt;/code> panel from the left navigation bar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Filter the route table either using the node/cluster names or network to be failed over (shown below).&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="route-table.png" alt="img">&lt;/p>
&lt;pre>&lt;code>a. If there is more than one network that needs to be routed to the secondary site using node/cluster names to filter is more efficient
&lt;/code>&lt;/pre>
&lt;ol>
&lt;li>Clear the destination field and start typing the name of the secondary site node/cluster. Select the appropriate node/cluster from the list.&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="destination-field.png" alt="img">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Click &lt;code>Save&lt;/code>. Then select &lt;code>Review Changes&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You should see a modified &lt;a href="/docs/domain/virtual-networks/routes/">route&lt;/a> for each network you adjusted showing the previous and current destination. If everything looks correct click &lt;code>Apply Changes&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="apply-changes.png" alt="img">&lt;/p>
&lt;ol>
&lt;li>It may take 1-2 minutes for nodes to pull down the updated routing table. Once that has completed any new flow or connection will automatically be sent to the new destination node.&lt;/li>
&lt;/ol>
&lt;div class="alert alert-primary" role="alert">
If the node/cluster is still online at the primary site, and there are existing flows/connections they will persist at that site. To clear them restart the active node at the primary site. See the last step in the Forcing Failover section below for instructions.
&lt;/div>
&lt;h4 id="failing-back">Failing Back&lt;/h4>
&lt;p>To send traffic back to the primary site reverse the changes in the routing performed during the failover.&lt;/p>
&lt;h3 id="automatic-failover">Automatic Failover&lt;/h3>
&lt;p>When a customer has selected automatic failover between sites there should be no intervention required if the primary site goes offline. The route table will be configured with multiple routes with different metrics. When determining where to send virtual traffic a node will select:&lt;/p>
&lt;ul>
&lt;li>The most specific route - meaning if there is a route for 192.168.100.1/32 and another for 192.168.100.0/24, the /32 route will be preferred&lt;/li>
&lt;li>With the lowest metric&lt;/li>
&lt;li>that is currently available - meaning this node has an active tunnel to the destination node/cluster&lt;/li>
&lt;/ul>
&lt;p>Below reflects a typical automatic failover configuration for a network&lt;/p>
&lt;h4 id="forcing-failover-or-prevent-auto-failback">Forcing Failover or Prevent Auto-Failback&lt;/h4>
&lt;p>If it is necessary to move traffic to the secondary site without the primary site going offline follow the below process.&lt;/p>
&lt;p>Also, if a failure of the primary site has occurred and you want to ensure traffic does not automatically return to that site if it comes online (e.g. it is unstable) you can follow the same process.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>In the portal, navigate to &lt;code>Domain&lt;/code> → &lt;code>Virtual Networks&lt;/code> and then select the appropriate Virtual network.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;code>Routes&lt;/code> from the left navigation bar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Filter the route table either using the node/cluster names or network to be failed over (shown below)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="route-table.png" alt="img">&lt;/p>
&lt;pre>&lt;code>a. If there is more than one network that needs to be routed to the secondary site using node/cluster names to filter is more efficient
&lt;/code>&lt;/pre>
&lt;ol>
&lt;li>Adjust the metric so that the primary site is a higher number than the secondary site. The maximum metric value is 200.&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="metric.png" alt="img">&lt;/p>
&lt;p>Click &lt;code>Save&lt;/code> and navigate to &lt;code>Review Changes&lt;/code>&lt;/p>
&lt;p>You should see a change like below for each route adjusted. Click &lt;code>Apply Changes&lt;/code> if all looks correct.&lt;/p>
&lt;p>&lt;img src="apply-changes-metric.png" alt="img">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>It may take 1-2 minutes for nodes to pull down the updated route table. At that point, they will route new flows/connections to the new destination.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Because the primary site is still online, you will need to restart the active node at that site to clear out any existing flows/connections.&lt;/p>
&lt;p>a. If it&amp;rsquo;s a cluster, navigate to the cluster and then select the currently active node from the overview page. If a single node site, navigate directly to that node.&lt;/p>
&lt;p>b. From the toolbar select &lt;code>Restart&lt;/code>&lt;/p>
&lt;p>c. Enter the node’s name and click &lt;code>confirm&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="restore-traffic-to-primary-site">Restore Traffic to Primary Site&lt;/h3>
&lt;p>To restore traffic to the primary site repeat the above steps but set the route for the primary site to have the lowest metric.&lt;/p></description></item></channel></rss>